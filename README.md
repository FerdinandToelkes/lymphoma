# Subtyping Lymphoma Whole Slide Images with Deep Learning

This project was part of my [master's thesis](toelkes_master_thesis_final_version.pdf) and its name has been changed afterwards to be more descriptive.

This project contains everything that happens after the .sqlite data generated by *pamly* was preprocessed by <a href="https://github.com/FerdinandToelkes/Patchcraft-Preparing-Whole-Slide-Images-for-Training-Neural-Networks" target="_blank">Patchcraft</a>. Since the code was mainly meant for personal usage, it is not in the form of a package and thus a bit less structured, than the Patchcraft code. Here, we give a brief overview of the project structure and the different parts of the project. Docker commands are provided in the respective scripts to run the code. 

## Outline

The general structure of the project is as follows:

1. [data_preparation](#data_preparation)
   - [after_patchcraft](#after_patchcraft)
   - [data_analysis](#data_analysis)
   - [data_annotation](#data_annotation)
   - [embedding_generation](#embedding_generation)
2. [resnet_ddp](#resnet_ddp)
   - [DDP_main script](#DDP_main-script)
   - [patch_level_eval script](#patch_level_eval-script)
   - [slide_level_eval script](#slide_level_eval-script)
   - [analyze_data_distributions script](#analyze_data_distributions-script)
   - [others](#others)
3. [uni_analysis](#uni_analysis)
4. [visualize_preprocessing](#visualize_preprocessing)

## data_preparation

The initial situation is as follows: Patches are sampled via <a href="https://github.com/FerdinandToelkes/Patchcraft-Preparing-Whole-Slide-Images-for-Training-Neural-Networks" target="_blank">Patchcraft</a> and saved as individual files in different directories. The data preparation directory contains script for further processing the data as well as analyzing it.

### after_patchcraft

This directory contains all scripts necessary to bring the data in the format later used for training as well as preparing for the generation of embeddings.

### data_analysis

This directory contains scripts for analyzing the data, i.e. the distribution of the different classes as well as how two dimensional representations compare between classes and different datasets.

### data_annotation

This directory contains scripts for annotating the data, i.e. generating csv files that can later be easily used by custom dataloader to efficiently load the data. Since we essentially employ nested cross-validation with one outer and five inner folds, we have to split the data accordingly.

### embedding_generation

This directory contains scripts for generating embeddings from the patches. We use the <a href="https://github.com/mahmoodlab/UNI" target="_blank">UNI</a> pretrained Vision Transformer to generate embeddings from the patches. The embeddings are then used to train a classifier. One has the possibility of generating embeddings from whole patches or from highly attended regions within the patches. 


## resnet_ddp

This directory contains scripts for training and evaluating a ResNet model with Distributed Data Parallel (DDP) on the embeddings generated by the UNI Vision Transformer. For training we employ a custom dataloader. Evaluation is can be done on the patch or slide level and it is split into an extra directory.

## uni_analysis

This directory contains scripts for analyzing the UNI embeddings. We compare the embeddings and attention maps generated from patches of different resolutions utilizing the mean squared error (MSE), the cosine similarity and an overlap metric especially designed for attention maps.

## visualize_preprocessing

This directory contains one script that was used to generate the figure for visualizing the preprocessing.

## Installation

Provide instructions on how to set up the project environment, including any dependencies and installation steps.

## Usage

To use this project, simply clone the repository, pip install the requirements and run the scripts in the respective directories. 

```bash
git clone
pip install -r requirements.txt
```

Note that paths need to be updated depending on the local setup especially of the data. 

## Contributing

If you would like to contribute to the project, please open an issue or a pull request.

## License

This project is licensed under the MIT License - see the LICENSE file for details.


